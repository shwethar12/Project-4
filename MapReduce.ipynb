{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>IMPORTING NECESSARY PACKAGES</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numapy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br><br><center>DATA CLEANING</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Cleaning(text_list):\n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    # Extracting individual lines from the list\n",
    "    for line in text_list:\n",
    "        \n",
    "        # Checking to amke sure it is not an empty line\n",
    "        if line!=\"\\n\":\n",
    "            \n",
    "            # Using regex to replace non characters & single space with space.\n",
    "            # Replacing with space to avoid concatenating words which have just punctuations between them\n",
    "            # Eg: \"myself--for\" in line 821 \n",
    "            cleaned_line = re.sub(r'[^a-zA-Z ]',\" \",line).lower()\n",
    "            \n",
    "    \n",
    "            # If line ends with a number (\"Chapter 1\") the word is followed by a space in the end after cleaning (\"chapter \")\n",
    "            # Removing such space by checking if the last character of the line is just a space \n",
    "            if cleaned_line.isspace()!= True:\n",
    "                if cleaned_line[-1:]==\" \":\n",
    "                    output.append(cleaned_line[:-1])\n",
    "                else:\n",
    "                    output.append(cleaned_line)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br><br><center>DATA SPLIT</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Split(cleansed_data):\n",
    "    \n",
    "    # Slicing first 5000 lines\n",
    "    output1 = cleansed_data[0:5000]\n",
    "    \n",
    "    # Slicing remaining lines\n",
    "    output2 = cleansed_data[5000:]\n",
    "    return output1, output2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br><br><center>MAPPER</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mapper1(text_lines):\n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    # Iterating each individual line from the list\n",
    "    for lines in text_lines:\n",
    "        \n",
    "        # Iterating each word in the line\n",
    "        for word in lines.split(\" \"):\n",
    "            # Ignoring if the word is an empty character\n",
    "            if word != \"\":\n",
    "                #  Creating a dictionay with word as key and value as 1 and appending the dictionary to the list\n",
    "                output.append({word: 1})\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "# Same logic as Mapper1 function above\n",
    "def Mapper2(text_lines):\n",
    "    output = []\n",
    "    \n",
    "    for lines in text_lines:\n",
    "        for word in lines.split(\" \"):\n",
    "            if word != \"\":\n",
    "                output.append({word: 1})\n",
    "\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br><br><center>SORT MAPPER OUTPUTS</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sort_Mapper(list_1, list_2):\n",
    "    \n",
    "    # Combining both lists\n",
    "    combined_list = list_1 + list_2\n",
    "    \n",
    "    words = []\n",
    "    \n",
    "    # Iterating each dictionary in the list\n",
    "    for dictionaries in combined_list:\n",
    "        \n",
    "        # Selecting keys(words) of individual dictionary and appending them to a list\n",
    "        for k, v in dictionaries.items():\n",
    "            words.append(k)\n",
    "    \n",
    "    # Extracting the indices by sorting the words alphabeltically\n",
    "    sorted_indices = list(np.argsort(words))\n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    # Using the sorted indices to rearrange and store the dictionaries of the combined list in a new list\n",
    "    for i in range(len(combined_list)):\n",
    "        output.append(combined_list[sorted_indices[i]])\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br><br><center>PARTITION</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Partition(sorted_list):\n",
    "    \n",
    "    # Checking the index for the first key(word) which starts with \"n\"\n",
    "    for i in range(len(sorted_list)):\n",
    "        if str(sorted_list[i].keys())[12] == \"n\":\n",
    "            n_index = i\n",
    "            break\n",
    "    \n",
    "    # List 1 contains keys(words) starting with letters \"a\" to \"m\"\n",
    "    # List 2 contains keys(words) starting with letters \"n\" to \"z\"\n",
    "    output1, output2 = sorted_list[:n_index], sorted_list[n_index:]\n",
    "    \n",
    "    return output1, output2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br><br><center>REDUCER</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reducer1(partition_output):\n",
    "    words_list = []\n",
    "    \n",
    "    # Appending keys from all the dictionaries in a ist  \n",
    "    for dictionaries in partition_output:\n",
    "        for k,v in dictionaries.items():\n",
    "            words_list.append(k)\n",
    "    \n",
    "    # Creating a list with a set of individual words \n",
    "    individual_words = sorted(list(set(words_list)))\n",
    "    index = 0\n",
    "    \n",
    "    # Dictionary to store key and its concatenated values\n",
    "    reducer_dict = {}\n",
    "    \n",
    "    # Concatenating key with all its values similar to the reducer function. Eg: {\"a\":[1,1,1,1....] , \"b\":[1,1,1,1....] , .....} \n",
    "    for word in individual_words:\n",
    "        values = []\n",
    "    \n",
    "        for text_word in words_list[index:]:\n",
    "        \n",
    "            if text_word == word:\n",
    "                values.append(int(str(partition_output[index].values())[-3]))\n",
    "                index+=1\n",
    "        \n",
    "            if text_word != word or index == len(words_list):\n",
    "                reducer_dict[word]=values\n",
    "                break\n",
    "    \n",
    "    ct=[]\n",
    "    \n",
    "    # Counting the frequency for each word by checking length of list with the concatenated values\n",
    "    for word in individual_words:\n",
    "        ct.append(len(reducer_dict[word]))    \n",
    "    \n",
    "    return individual_words, ct\n",
    "\n",
    "\n",
    "# Implemeted using same logis as Reducer1 function\n",
    "def Reducer2(partition_output):\n",
    "    words_list = []\n",
    "\n",
    "    for dictionaries in partition_output:\n",
    "        for k,v in dictionaries.items():\n",
    "            words_list.append(k)\n",
    "\n",
    "    individual_words = sorted(list(set(words_list)))\n",
    "    index = 0\n",
    "    reducer_dict = {}\n",
    "\n",
    "    for word in individual_words:\n",
    "        values = []\n",
    "    \n",
    "        for text_word in words_list[index:]:\n",
    "        \n",
    "            if text_word == word:\n",
    "                values.append(int(str(partition_output[index].values())[-3]))\n",
    "                index+=1\n",
    "        \n",
    "            if text_word != word or index == len(words_list):\n",
    "                reducer_dict[word]=values\n",
    "                break\n",
    "    \n",
    "    ct=[]\n",
    "    \n",
    "    for word in individual_words:\n",
    "        ct.append(len(reducer_dict[word]))    \n",
    "    \n",
    "    return individual_words, ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br><br><center>MAIN FUNCTION (MAPREDUCE)</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Map_Reduce(file_name):\n",
    "    \n",
    "    # Storing each line of the text as an individual elemnt of  a list \n",
    "    with open(file_name,\"r\") as file:\n",
    "        book = file.readlines()\n",
    "    \n",
    "    # Calling Data Cleaning function\n",
    "    cleansed_data = Data_Cleaning(book)\n",
    "    \n",
    "    # Calling Data Split  to split data on 5000th line\n",
    "    part1 , part2 = Data_Split(cleansed_data)\n",
    "    \n",
    "    # Calling both mapper functions with the split data as arguments to form key value pairs\n",
    "    mapper1_output , mapper2_output = Mapper1(part1), Mapper2(part2)\n",
    "    \n",
    "    # Calling Sort function to sort the combined output of both mappers \n",
    "    sort_output = Sort_Mapper(mapper1_output , mapper2_output)\n",
    "    \n",
    "    # Calling partition function to split sorted result into two lists, \n",
    "    # one for words starting with \"a\" to \"m\" and another for words starting with \"n\" to \"z\"\n",
    "    partition_output1 , partition_output2 = Partition(sort_output)\n",
    "    \n",
    "    # Calling reducer function to count the frequency of each individual word\n",
    "    reducer1_words , reducer1_frequency = Reducer1(partition_output1)\n",
    "    reducer2_words , reducer2_frequency = Reducer2(partition_output2)\n",
    "\n",
    "    # Concatenating the reducer output into a dataframe\n",
    "    final_output = pd.DataFrame()\n",
    "    final_output[\"Word\"] = reducer1_words + reducer2_words\n",
    "    final_output[\"Frequency\"] = reducer1_frequency + reducer2_frequency\n",
    "    \n",
    "    # Storing the results in a csv file\n",
    "    final_output.to_csv(\"Group10_Assignment1.csv\", index=False)\n",
    "    \n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br><br><center>CALLING MAPREDUCE FUNCTION</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter name of file. File needs to be stored in the current working directory\n",
    "file_name = \"Pride_and_Prejudice.txt\"\n",
    "\n",
    "# Calling the Main Function (Map_Reduce)\n",
    "Map_Reduce_Output = Map_Reduce(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abatement</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abhorrence</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abhorrent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abiding</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abilities</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>able</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ablution</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abode</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>abominable</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word  Frequency\n",
       "0            a       1954\n",
       "1    abatement          1\n",
       "2   abhorrence          6\n",
       "3    abhorrent          1\n",
       "4        abide          1\n",
       "5      abiding          1\n",
       "6    abilities          6\n",
       "7         able         54\n",
       "8     ablution          1\n",
       "9        abode          8\n",
       "10  abominable          6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Map_Reduce_Output.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6248</th>\n",
       "      <td>you</td>\n",
       "      <td>1358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249</th>\n",
       "      <td>young</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6250</th>\n",
       "      <td>younge</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6251</th>\n",
       "      <td>younger</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>youngest</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6253</th>\n",
       "      <td>your</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6254</th>\n",
       "      <td>yours</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6255</th>\n",
       "      <td>yourself</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6256</th>\n",
       "      <td>yourselves</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6257</th>\n",
       "      <td>youth</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6258</th>\n",
       "      <td>youths</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  Frequency\n",
       "6248         you       1358\n",
       "6249       young        130\n",
       "6250      younge          4\n",
       "6251     younger         30\n",
       "6252    youngest         13\n",
       "6253        your        456\n",
       "6254       yours         23\n",
       "6255    yourself         50\n",
       "6256  yourselves          2\n",
       "6257       youth          9\n",
       "6258      youths          1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Map_Reduce_Output.tail(11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
